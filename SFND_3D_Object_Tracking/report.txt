--------------------MP1--------------------------------
This is the task where we match the corresponding bounding boxes between the frames. First we iterate through the list of matches to find points that are present in bounding box of both previous and current frame. This gives a partial information that bounding boxes sharing matches could represent the same entity.Then we create a cost matrix . The table is such that rows will be bounding boxes of prev frame and columns will be bounding boxes of current frame. We iterate over the list of maps we created in our first process. eventually we know that some set of bounding boxes share maximum number of keypoints this is represented by rows and its corresponding max value on its respective column.This will give us map of related bounding boxes between the frames.
-------------------MP2---------------------------------
Here we calculate ttc by using lidar and below formula
TTC = minXCurr * dT / (minXPrev-minXCurr);
Here we try to associate lidar Points from previous frame to current frame and using the change in distances calculate TTC. In our case the object of interest to use for ttc calculation is the point cloud closest to the front of ego vehicle.However these may have some issues as due to noise points detected as minimum and used in calculation may not have any relation to vehicle and could very well be ghost points.This is easily noticed in 3D_track xlsx file. I think one way to may be overcome this issue is using centroid of the respective cluster. I think this could give more accurate and stable estimates.
-------------------MP3-----------------------------
This is a section where we associate keypoint with the given bounding box. However it must be noted that sometimes matches can be off so we need to come up with a threshold to figure out if given match is actually what it say its is . Here one metric we can take is how far all points move when compared between current and previous frame. The avg of this distance is taken as distance threshold. So any matches that seem to have distances more than threshold gets filtered out . Rest of the points are attached to keypoints of the bounding Box.
------------------MP4------------------------------
In this section we try to calculate TTC using associated keypoints within the 2 images.This formula given below is used
TTC = -dT / (1 - medDistRatio);
Here basic idea is by observing keypoints in current and previous images we can detect the change is scale thus the time to collision.The algorithms goes like this we try to get dist ratios by using two matched pairs .Note that this holds information related to two keypoints with in the respective frame and thus gives us a clue on scale of image.Then median of the values are taken to reduce any influence of outliers assuming a major portion of our observed data is corresponding to reality.
This did have issues of some of the chart calculations shows -inf and even triple digit estimate of time to collision.
-----------------MP5&MP6---------------------------
The sampled results are recorded in 3D_track.xlsx. 
One common deviance occured in TTC lidar at 20-22 frame where the estimates were in the range of -10 or somewhere like 30-50 , I think this is because the mechanism by which the reference lidar points are chosen might be issue as some ghost lidar points must be influencing this outcome.So may be centroid of cluster could provide us with good estimates?
The TTC camera was relatively stable and accurate for most part compared to camera. we occasionaly see inf thats when we dont find enough keypoint associated with a bounding box in MP3. This could be result of lot of inaccurate matches
By comparing observations of midterm project and current observation of stable ttc estimates gives FAST+BRIEF as the perfect goldilock configuration. Balancing between amazing matching performance and good stable estimation.